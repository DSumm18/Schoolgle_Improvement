{"version":3,"sources":["../../src/credit/index.ts","../../src/models/openrouter.ts","../../src/models/router.ts","../../src/credit/manager.ts"],"sourcesContent":["/**\r\n * Credit module exports\r\n */\r\n\r\nexport * from './manager';\r\n","/**\r\n * OpenRouter Client\r\n * Unified model access via OpenRouter API\r\n */\r\n\r\nimport type { ModelConfig, TokenUsage } from '../types';\r\n\r\n// ============================================================================\r\n// Configuration\r\n// ============================================================================\r\n\r\nexport interface OpenRouterConfig {\r\n  apiKey: string;\r\n  baseURL?: string;\r\n  timeout?: number;\r\n}\r\n\r\n// ============================================================================\r\n// Available Models on OpenRouter\r\n// ============================================================================\r\n\r\n/**\r\n * Model catalog with OpenRouter model IDs\r\n * Costs are approximate and may change - check openrouter.ai/docs for current pricing\r\n */\r\nexport const OPENROUTER_MODELS: Record<string, ModelConfig> = {\r\n  // ========== PREMIUM MODELS (High quality, higher cost) ==========\r\n\r\n  'anthropic/claude-3.5-sonnet': {\r\n    id: 'anthropic/claude-3.5-sonnet',\r\n    provider: 'openrouter',\r\n    model: 'anthropic/claude-3.5-sonnet',\r\n    costPerMillionTokens: 3.00, // Input, output is ~$15\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  'anthropic/claude-3.5-sonnet:beta': {\r\n    id: 'anthropic/claude-3.5-sonnet:beta',\r\n    provider: 'openrouter',\r\n    model: 'anthropic/claude-3.5-sonnet:beta',\r\n    costPerMillionTokens: 3.00,\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  'openai/gpt-4o': {\r\n    id: 'openai/gpt-4o',\r\n    provider: 'openrouter',\r\n    model: 'openai/gpt-4o',\r\n    costPerMillionTokens: 2.50, // Input, output is ~$10\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  'google/gemini-2.0-flash-exp': {\r\n    id: 'google/gemini-2.0-flash-exp',\r\n    provider: 'openrouter',\r\n    model: 'google/gemini-2.0-flash-exp',\r\n    costPerMillionTokens: 0.075, // Very cheap!\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  'google/gemini-2.5-pro': {\r\n    id: 'google/gemini-2.5-pro',\r\n    provider: 'openrouter',\r\n    model: 'google/gemini-2.5-pro',\r\n    costPerMillionTokens: 1.25,\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  'google/gemini-2.5-flash-thinking-exp': {\r\n    id: 'google/gemini-2.5-flash-thinking-exp',\r\n    provider: 'openrouter',\r\n    model: 'google/gemini-2.5-flash-thinking-exp',\r\n    costPerMillionTokens: 0.10,\r\n    capabilities: {\r\n      vision: false,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  // ========== FAST CHEAP MODELS (Routing, classification) ==========\r\n\r\n  'openai/gpt-4o-mini': {\r\n    id: 'openai/gpt-4o-mini',\r\n    provider: 'openrouter',\r\n    model: 'openai/gpt-4o-mini',\r\n    costPerMillionTokens: 0.15, // Input, output is ~$0.60\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  'deepseek/deepseek-chat': {\r\n    id: 'deepseek/deepseek-chat',\r\n    provider: 'openrouter',\r\n    model: 'deepseek/deepseek-chat',\r\n    costPerMillionTokens: 0.27, // Input, output is ~$1.10\r\n    capabilities: {\r\n      vision: false,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  'deepseek/deepseek-chat-v3-0324': {\r\n    id: 'deepseek/deepseek-chat-v3-0324',\r\n    provider: 'openrouter',\r\n    model: 'deepseek/deepseek-chat-v3-0324',\r\n    costPerMillionTokens: 0.27,\r\n    capabilities: {\r\n      vision: false,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  'deepseek/deepseek-r1': {\r\n    id: 'deepseek/deepseek-r1',\r\n    provider: 'openrouter',\r\n    model: 'deepseek/deepseek-r1',\r\n    costPerMillionTokens: 0.55, // Reasoning model\r\n    capabilities: {\r\n      vision: false,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  // ========== ULTRA-CHEAP MODELS ==========\r\n\r\n  // Note: Free models change frequently - check openrouter.ai for current free options\r\n\r\n  // ========== VISION MODELS ==========\r\n\r\n  'anthropic/claude-3.5-sonnet': {\r\n    id: 'anthropic/claude-3.5-sonnet',\r\n    provider: 'openrouter',\r\n    model: 'anthropic/claude-3.5-sonnet',\r\n    costPerMillionTokens: 3.00,\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  'openai/gpt-4o': {\r\n    id: 'openai/gpt-4o',\r\n    provider: 'openrouter',\r\n    model: 'openai/gpt-4o',\r\n    costPerMillionTokens: 2.50,\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  'google/gemini-2.0-flash-exp': {\r\n    id: 'google/gemini-2.0-flash-exp',\r\n    provider: 'openrouter',\r\n    model: 'google/gemini-2.0-flash-exp',\r\n    costPerMillionTokens: 0.075,\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  // ========== REASONING MODELS ==========\r\n\r\n  'deepseek/deepseek-r1': {\r\n    id: 'deepseek/deepseek-r1',\r\n    provider: 'openrouter',\r\n    model: 'deepseek/deepseek-r1',\r\n    costPerMillionTokens: 0.55,\r\n    capabilities: {\r\n      vision: false,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n};\r\n\r\n/**\r\n * Model aliases for easy reference\r\n */\r\nexport const MODEL_ALIASES: Record<string, string> = {\r\n  // Primary models\r\n  'premium': 'anthropic/claude-3.5-sonnet',\r\n  'fast': 'openai/gpt-4o-mini',\r\n  'cheap': 'deepseek/deepseek-chat',\r\n\r\n  // Specific model aliases\r\n  'claude': 'anthropic/claude-3.5-sonnet',\r\n  'gpt4': 'openai/gpt-4o',\r\n  'gpt4-mini': 'openai/gpt-4o-mini',\r\n  'gemini': 'google/gemini-2.5-flash-thinking-exp',\r\n  'deepseek': 'deepseek/deepseek-chat',\r\n  'deepseek-r1': 'deepseek/deepseek-r1',\r\n};\r\n\r\n// ============================================================================\r\n// OpenRouter Client Class\r\n// ============================================================================\r\n\r\nexport interface ChatMessage {\r\n  role: 'system' | 'user' | 'assistant';\r\n  content: string;\r\n}\r\n\r\nexport interface ChatOptions {\r\n  model?: string;\r\n  temperature?: number;\r\n  maxTokens?: number;\r\n  topP?: number;\r\n  stream?: boolean;\r\n}\r\n\r\nexport interface ChatResponse {\r\n  content: string;\r\n  model: string;\r\n  usage: {\r\n    promptTokens: number;\r\n    completionTokens: number;\r\n    totalTokens: number;\r\n  };\r\n  finishReason?: string;\r\n}\r\n\r\n/**\r\n * OpenRouter API Client\r\n */\r\nexport class OpenRouterClient {\r\n  private config: OpenRouterConfig;\r\n  private baseURL: string;\r\n\r\n  constructor(config: OpenRouterConfig) {\r\n    this.config = config;\r\n    this.baseURL = config.baseURL || 'https://openrouter.ai/api/v1';\r\n  }\r\n\r\n  /**\r\n   * Send a chat completion request\r\n   */\r\n  async chat(\r\n    messages: ChatMessage[],\r\n    options: ChatOptions = {}\r\n  ): Promise<ChatResponse> {\r\n    const model = options.model || 'anthropic/claude-3.5-sonnet';\r\n\r\n    const requestBody = {\r\n      model,\r\n      messages: messages.map(m => ({\r\n        role: m.role,\r\n        content: m.content,\r\n      })),\r\n      temperature: options.temperature ?? 0.7,\r\n      max_tokens: options.maxTokens ?? 4096,\r\n      top_p: options.topP,\r\n      stream: options.stream ?? false,\r\n    };\r\n\r\n    const response = await fetch(`${this.baseURL}/chat/completions`, {\r\n      method: 'POST',\r\n      headers: {\r\n        'Authorization': `Bearer ${this.config.apiKey}`,\r\n        'Content-Type': 'application/json',\r\n        'HTTP-Referer': typeof window !== 'undefined' ? window.location.href : 'https://schoolgle.co.uk',\r\n        'X-Title': 'Schoolgle Ed',\r\n      },\r\n      body: JSON.stringify(requestBody),\r\n      signal: options.timeout ? AbortSignal.timeout(options.timeout) : undefined,\r\n    });\r\n\r\n    if (!response.ok) {\r\n      const errorText = await response.text();\r\n      throw new OpenRouterError(\r\n        `OpenRouter API error: ${response.status} ${response.statusText}`,\r\n        response.status,\r\n        errorText\r\n      );\r\n    }\r\n\r\n    const data = await response.json();\r\n\r\n    // Extract response\r\n    const choice = data.choices?.[0];\r\n    if (!choice) {\r\n      throw new OpenRouterError('No choices returned from OpenRouter', 500);\r\n    }\r\n\r\n    return {\r\n      content: choice.message?.content || '',\r\n      model: data.model || model,\r\n      usage: {\r\n        promptTokens: data.usage?.prompt_tokens || 0,\r\n        completionTokens: data.usage?.completion_tokens || 0,\r\n        totalTokens: data.usage?.total_tokens || 0,\r\n      },\r\n      finishReason: choice.finish_reason,\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Send a chat completion request with system prompt\r\n   */\r\n  async chatWithSystem(\r\n    systemPrompt: string,\r\n    userMessage: string,\r\n    options: ChatOptions = {}\r\n  ): Promise<ChatResponse> {\r\n    return this.chat(\r\n      [\r\n        { role: 'system', content: systemPrompt },\r\n        { role: 'user', content: userMessage },\r\n      ],\r\n      options\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Stream a chat completion (for future implementation)\r\n   */\r\n  async *chatStream(\r\n    messages: ChatMessage[],\r\n    options: ChatOptions = {}\r\n  ): AsyncGenerator<string, void, unknown> {\r\n    const model = options.model || 'anthropic/claude-3.5-sonnet';\r\n\r\n    const requestBody = {\r\n      model,\r\n      messages: messages.map(m => ({\r\n        role: m.role,\r\n        content: m.content,\r\n      })),\r\n      temperature: options.temperature ?? 0.7,\r\n      max_tokens: options.maxTokens ?? 4096,\r\n      stream: true,\r\n    };\r\n\r\n    const response = await fetch(`${this.baseURL}/chat/completions`, {\r\n      method: 'POST',\r\n      headers: {\r\n        'Authorization': `Bearer ${this.config.apiKey}`,\r\n        'Content-Type': 'application/json',\r\n        'HTTP-Referer': 'https://schoolgle.co.uk',\r\n        'X-Title': 'Schoolgle Ed',\r\n      },\r\n      body: JSON.stringify(requestBody),\r\n    });\r\n\r\n    if (!response.ok) {\r\n      throw new OpenRouterError(\r\n        `OpenRouter API error: ${response.status} ${response.statusText}`,\r\n        response.status\r\n      );\r\n    }\r\n\r\n    // Stream parsing\r\n    const reader = response.body?.getReader();\r\n    if (!reader) throw new OpenRouterError('No response body', 500);\r\n\r\n    const decoder = new TextDecoder();\r\n\r\n    try {\r\n      while (true) {\r\n        const { done, value } = await reader.read();\r\n        if (done) break;\r\n\r\n        const chunk = decoder.decode(value);\r\n        const lines = chunk.split('\\n').filter(line => line.trim());\r\n\r\n        for (const line of lines) {\r\n          if (line.startsWith('data: ')) {\r\n            const data = line.slice(6);\r\n            if (data === '[DONE]') return;\r\n\r\n            try {\r\n              const parsed = JSON.parse(data);\r\n              const content = parsed.choices?.[0]?.delta?.content;\r\n              if (content) yield content;\r\n            } catch {\r\n              // Skip invalid JSON\r\n            }\r\n          }\r\n        }\r\n      }\r\n    } finally {\r\n      reader.releaseLock();\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Get model info\r\n   */\r\n  getModel(modelIdOrAlias: string): ModelConfig | undefined {\r\n    // Resolve alias\r\n    const modelId = MODEL_ALIASES[modelIdOrAlias] || modelIdOrAlias;\r\n    return OPENROUTER_MODELS[modelId];\r\n  }\r\n\r\n  /**\r\n   * Get all available models\r\n   */\r\n  getAllModels(): Record<string, ModelConfig> {\r\n    return { ...OPENROUTER_MODELS };\r\n  }\r\n}\r\n\r\n// ============================================================================\r\n// Error Class\r\n// ============================================================================\r\n\r\nexport class OpenRouterError extends Error {\r\n  constructor(\r\n    message: string,\r\n    public statusCode: number,\r\n    public responseText?: string\r\n  ) {\r\n    super(message);\r\n    this.name = 'OpenRouterError';\r\n  }\r\n}\r\n\r\n// ============================================================================\r\n// Utility Functions\r\n// ============================================================================\r\n\r\n/**\r\n * Create OpenRouter client from environment\r\n */\r\nexport function createOpenRouterClient(): OpenRouterClient {\r\n  const apiKey = process.env.OPENROUTER_API_KEY || '';\r\n\r\n  if (!apiKey) {\r\n    throw new Error('OPENROUTER_API_KEY environment variable is not set');\r\n  }\r\n\r\n  return new OpenRouterClient({\r\n    apiKey,\r\n    timeout: 30000, // 30 second default\r\n  });\r\n}\r\n\r\n/**\r\n * Calculate token cost\r\n */\r\nexport function calculateTokenCost(\r\n  modelId: string,\r\n  inputTokens: number,\r\n  outputTokens: number\r\n): number {\r\n  const model = OPENROUTER_MODELS[modelId];\r\n  if (!model) return 0;\r\n\r\n  // Note: OpenRouter pricing can vary by provider\r\n  // This is an approximation using the base cost per million tokens\r\n  const inputCost = (inputTokens / 1_000_000) * model.costPerMillionTokens;\r\n  const outputCost = (outputTokens / 1_000_000) * (model.costPerMillionTokens * 3); // Rough estimate\r\n\r\n  return inputCost + outputCost;\r\n}\r\n","/**\r\n * Model Router\r\n * Selects the best model for each task using OpenRouter\r\n */\r\n\r\nimport type { ModelConfig, TaskType, AppContext } from '../types';\r\nimport {\r\n  OPENROUTER_MODELS,\r\n  MODEL_ALIASES,\r\n  createOpenRouterClient,\r\n  calculateTokenCost as calculateORCost,\r\n  type ChatMessage,\r\n  type ChatOptions,\r\n  type ChatResponse,\r\n} from './openrouter';\r\n\r\n// ============================================================================\r\n// Task-to-Model Mapping\r\n// ============================================================================\r\n\r\n/**\r\n * Default model selection by task type\r\n * Ordered by preference (first is optimal, last is fallback)\r\n */\r\nconst TASK_MODEL_MAP: Record<TaskType, string[]> = {\r\n  // Fast/cheap for routing\r\n  'intent-classification': ['openai/gpt-4o-mini', 'google/gemini-2.0-flash-exp', 'deepseek/deepseek-chat'],\r\n  'work-focus-check': ['openai/gpt-4o-mini', 'google/gemini-2.0-flash-exp'],\r\n\r\n  // High quality for specialist responses\r\n  'specialist-response': ['anthropic/claude-3.5-sonnet', 'deepseek/deepseek-chat', 'openai/gpt-4o'],\r\n  'perspective-generation': ['deepseek/deepseek-chat', 'openai/gpt-4o-mini', 'google/gemini-2.0-flash-exp'],\r\n  'synthesis': ['anthropic/claude-3.5-sonnet', 'deepseek/deepseek-chat'],\r\n\r\n  // Vision needed\r\n  'ui-analysis': ['anthropic/claude-3.5-sonnet', 'openai/gpt-4o', 'google/gemini-2.5-pro'],\r\n\r\n  // Fast/cheap for actions\r\n  'action-planning': ['openai/gpt-4o-mini', 'google/gemini-2.0-flash-exp'],\r\n};\r\n\r\n/**\r\n * Plan-based model constraints\r\n */\r\nconst PLAN_MODEL_CONSTRAINTS: Record<string, string[]> = {\r\n  'free': ['openai/gpt-4o-mini', 'google/gemini-2.0-flash-exp', 'deepseek/deepseek-chat'],\r\n  'schools': ['anthropic/claude-3.5-sonnet', 'deepseek/deepseek-chat', 'openai/gpt-4o', 'google/gemini-2.0-flash-exp'],\r\n  'trusts': ['anthropic/claude-3.5-sonnet', 'deepseek/deepseek-r1', 'openai/gpt-4o'],\r\n};\r\n\r\n// ============================================================================\r\n// Model Router\r\n// ============================================================================\r\n\r\n/**\r\n * Model Router class\r\n */\r\nexport class ModelRouter {\r\n  private client: ReturnType<typeof createOpenRouterClient>;\r\n\r\n  constructor() {\r\n    this.client = createOpenRouterClient();\r\n  }\r\n\r\n  /**\r\n   * Select the best model for a given task based on context\r\n   */\r\n  selectModel(task: TaskType, context: AppContext): ModelConfig {\r\n    const availableModels = TASK_MODEL_MAP[task] || TASK_MODEL_MAP['specialist-response'];\r\n    const { plan, creditsRemaining } = context.subscription;\r\n\r\n    // Filter models by plan\r\n    const planModels = PLAN_MODEL_CONSTRAINTS[plan] || availableModels;\r\n    const eligibleModels = availableModels.filter(m => planModels.includes(m));\r\n\r\n    // If low credits, use cheapest option\r\n    if (creditsRemaining < 1000) {\r\n      return this.getCheapestModel(eligibleModels);\r\n    }\r\n\r\n    // Otherwise use optimal (first) model\r\n    const modelId = eligibleModels[0];\r\n    const model = OPENROUTER_MODELS[modelId];\r\n\r\n    if (!model) {\r\n      throw new Error(`Model not found: ${modelId}`);\r\n    }\r\n\r\n    return model;\r\n  }\r\n\r\n  /**\r\n   * Send chat completion request\r\n   */\r\n  async chat(\r\n    systemPrompt: string,\r\n    userMessage: string,\r\n    options: ChatOptions = {}\r\n  ): Promise<ChatResponse> {\r\n    return this.client.chatWithSystem(systemPrompt, userMessage, options);\r\n  }\r\n\r\n  /**\r\n   * Send chat completion with message array\r\n   */\r\n  async chatMessages(\r\n    messages: ChatMessage[],\r\n    options: ChatOptions = {}\r\n  ): Promise<ChatResponse> {\r\n    return this.client.chat(messages, options);\r\n  }\r\n\r\n  /**\r\n   * Stream chat completion (for future use)\r\n   */\r\n  async *chatStream(\r\n    messages: ChatMessage[],\r\n    options: ChatOptions = {}\r\n  ): AsyncGenerator<string> {\r\n    yield* this.client.chatStream(messages, options);\r\n  }\r\n\r\n  /**\r\n   * Get cheapest model from list\r\n   */\r\n  private getCheapestModel(modelIds: string[]): ModelConfig {\r\n    let cheapest = OPENROUTER_MODELS[modelIds[0]];\r\n    let lowestCost = cheapest?.costPerMillionTokens || Infinity;\r\n\r\n    for (const modelId of modelIds) {\r\n      const model = OPENROUTER_MODELS[modelId];\r\n      if (model && model.costPerMillionTokens < lowestCost) {\r\n        cheapest = model;\r\n        lowestCost = model.costPerMillionTokens;\r\n      }\r\n    }\r\n\r\n    return cheapest || OPENROUTER_MODELS['openai/gpt-4o-mini'];\r\n  }\r\n\r\n  /**\r\n   * Get model by ID or alias\r\n   */\r\n  getModel(idOrAlias: string): ModelConfig | undefined {\r\n    const modelId = MODEL_ALIASES[idOrAlias] || idOrAlias;\r\n    return OPENROUTER_MODELS[modelId];\r\n  }\r\n\r\n  /**\r\n   * Get all available models\r\n   */\r\n  getAllModels(): Record<string, ModelConfig> {\r\n    return { ...OPENROUTER_MODELS };\r\n  }\r\n}\r\n\r\n// Singleton instance\r\nlet routerInstance: ModelRouter | null = null;\r\n\r\n/**\r\n * Get or create model router instance\r\n */\r\nexport function getModelRouter(): ModelRouter {\r\n  if (!routerInstance) {\r\n    routerInstance = new ModelRouter();\r\n  }\r\n  return routerInstance;\r\n}\r\n\r\n// ============================================================================\r\n// Legacy Compatibility Functions\r\n// ============================================================================\r\n\r\n/**\r\n * Select model for task (legacy function signature)\r\n */\r\nexport async function selectModel(\r\n  task: TaskType,\r\n  context: AppContext\r\n): Promise<ModelConfig> {\r\n  const router = getModelRouter();\r\n  return router.selectModel(task, context);\r\n}\r\n\r\n/**\r\n * Check credits (simplified)\r\n */\r\nexport async function checkCredits(subscription: { creditsRemaining: number }): Promise<{\r\n  sufficient: boolean;\r\n  estimatedCost: number;\r\n}> {\r\n  // Estimate for typical query\r\n  const estimatedTokens = 1000;\r\n  const model = OPENROUTER_MODELS['google/gemini-2.0-flash-exp'];\r\n  const estimatedCost = (estimatedTokens / 1_000_000) * model.costPerMillionTokens;\r\n\r\n  return {\r\n    sufficient: subscription.creditsRemaining > estimatedCost,\r\n    estimatedCost,\r\n  };\r\n}\r\n\r\n/**\r\n * Calculate cost\r\n */\r\nexport function calculateCost(\r\n  modelId: string,\r\n  inputTokens: number,\r\n  outputTokens: number\r\n): number {\r\n  return calculateORCost(modelId, inputTokens, outputTokens);\r\n}\r\n\r\n/**\r\n * Get model by ID\r\n */\r\nexport function getModel(id: string): ModelConfig | undefined {\r\n  const router = getModelRouter();\r\n  return router.getModel(id);\r\n}\r\n\r\n/**\r\n * Get all models\r\n */\r\nexport function getAllModels(): Record<string, ModelConfig> {\r\n  const router = getModelRouter();\r\n  return router.getAllModels();\r\n}\r\n","/**\r\n * Credit Manager\r\n * Tracks and manages credit usage\r\n */\r\n\r\nimport type { TokenUsage, SubscriptionContext } from '../types';\r\nimport { calculateCost } from '../models/router';\r\n\r\n/**\r\n * Credit manager state\r\n */\r\ninterface CreditState {\r\n  subscription: SubscriptionContext;\r\n  sessionUsage: number;\r\n  lastReset: Date;\r\n}\r\n\r\n/**\r\n * Credit Manager class\r\n */\r\nexport class CreditManager {\r\n  private state: CreditState;\r\n\r\n  constructor(subscription: SubscriptionContext) {\r\n    this.state = {\r\n      subscription,\r\n      sessionUsage: 0,\r\n      lastReset: new Date(),\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Track credit usage for a request\r\n   */\r\n  trackUsage(modelId: string, inputTokens: number, outputTokens: number): TokenUsage {\r\n    const cost = calculateCost(modelId, inputTokens, outputTokens);\r\n    const totalTokens = inputTokens + outputTokens;\r\n\r\n    this.state.sessionUsage += cost;\r\n\r\n    return {\r\n      input: inputTokens,\r\n      output: outputTokens,\r\n      total: totalTokens,\r\n      cost,\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Get remaining credits\r\n   */\r\n  getRemainingCredits(): number {\r\n    return Math.max(0, this.state.subscription.creditsRemaining - this.state.sessionUsage);\r\n  }\r\n\r\n  /**\r\n   * Get session usage\r\n   */\r\n  getSessionUsage(): number {\r\n    return this.state.sessionUsage;\r\n  }\r\n\r\n  /**\r\n   * Check if user has sufficient credits\r\n   */\r\n  hasSufficientCredits(estimatedCost: number): boolean {\r\n    return this.getRemainingCredits() >= estimatedCost;\r\n  }\r\n\r\n  /**\r\n   * Get subscription plan\r\n   */\r\n  getPlan(): SubscriptionContext['plan'] {\r\n    return this.state.subscription.plan;\r\n  }\r\n\r\n  /**\r\n   * Update subscription (e.g., after credits purchased)\r\n   */\r\n  updateSubscription(subscription: Partial<SubscriptionContext>): void {\r\n    this.state.subscription = { ...this.state.subscription, ...subscription };\r\n  }\r\n\r\n  /**\r\n   * Get credit usage summary\r\n   */\r\n  getSummary(): {\r\n    plan: string;\r\n    creditsRemaining: number;\r\n    sessionUsage: number;\r\n    estimatedRemaining: number;\r\n  } {\r\n    return {\r\n      plan: this.state.subscription.plan,\r\n      creditsRemaining: this.state.subscription.creditsRemaining,\r\n      sessionUsage: this.state.sessionUsage,\r\n      estimatedRemaining: this.getRemainingCredits(),\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Reset session usage\r\n   */\r\n  resetSession(): void {\r\n    this.state.sessionUsage = 0;\r\n    this.state.lastReset = new Date();\r\n  }\r\n}\r\n\r\n/**\r\n * Create a credit manager from subscription context\r\n */\r\nexport function createCreditManager(subscription: SubscriptionContext): CreditManager {\r\n  return new CreditManager(subscription);\r\n}\r\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACyBO,IAAM,oBAAiD;AAAA;AAAA,EAG5D,+BAA+B;AAAA,IAC7B,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,oCAAoC;AAAA,IAClC,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,iBAAiB;AAAA,IACf,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,+BAA+B;AAAA,IAC7B,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,yBAAyB;AAAA,IACvB,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,wCAAwC;AAAA,IACtC,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA;AAAA,EAIA,sBAAsB;AAAA,IACpB,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,0BAA0B;AAAA,IACxB,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,kCAAkC;AAAA,IAChC,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,wBAAwB;AAAA,IACtB,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAQA,+BAA+B;AAAA,IAC7B,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,iBAAiB;AAAA,IACf,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,+BAA+B;AAAA,IAC7B,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA;AAAA,EAIA,wBAAwB;AAAA,IACtB,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AACF;AA0QO,SAAS,mBACd,SACA,aACA,cACQ;AACR,QAAM,QAAQ,kBAAkB,OAAO;AACvC,MAAI,CAAC,MAAO,QAAO;AAInB,QAAM,YAAa,cAAc,MAAa,MAAM;AACpD,QAAM,aAAc,eAAe,OAAc,MAAM,uBAAuB;AAE9E,SAAO,YAAY;AACrB;;;ACxRO,SAAS,cACd,SACA,aACA,cACQ;AACR,SAAO,mBAAgB,SAAS,aAAa,YAAY;AAC3D;;;AC/LO,IAAM,gBAAN,MAAoB;AAAA,EAGzB,YAAY,cAAmC;AAC7C,SAAK,QAAQ;AAAA,MACX;AAAA,MACA,cAAc;AAAA,MACd,WAAW,oBAAI,KAAK;AAAA,IACtB;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,WAAW,SAAiB,aAAqB,cAAkC;AACjF,UAAM,OAAO,cAAc,SAAS,aAAa,YAAY;AAC7D,UAAM,cAAc,cAAc;AAElC,SAAK,MAAM,gBAAgB;AAE3B,WAAO;AAAA,MACL,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,OAAO;AAAA,MACP;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,sBAA8B;AAC5B,WAAO,KAAK,IAAI,GAAG,KAAK,MAAM,aAAa,mBAAmB,KAAK,MAAM,YAAY;AAAA,EACvF;AAAA;AAAA;AAAA;AAAA,EAKA,kBAA0B;AACxB,WAAO,KAAK,MAAM;AAAA,EACpB;AAAA;AAAA;AAAA;AAAA,EAKA,qBAAqB,eAAgC;AACnD,WAAO,KAAK,oBAAoB,KAAK;AAAA,EACvC;AAAA;AAAA;AAAA;AAAA,EAKA,UAAuC;AACrC,WAAO,KAAK,MAAM,aAAa;AAAA,EACjC;AAAA;AAAA;AAAA;AAAA,EAKA,mBAAmB,cAAkD;AACnE,SAAK,MAAM,eAAe,kCAAK,KAAK,MAAM,eAAiB;AAAA,EAC7D;AAAA;AAAA;AAAA;AAAA,EAKA,aAKE;AACA,WAAO;AAAA,MACL,MAAM,KAAK,MAAM,aAAa;AAAA,MAC9B,kBAAkB,KAAK,MAAM,aAAa;AAAA,MAC1C,cAAc,KAAK,MAAM;AAAA,MACzB,oBAAoB,KAAK,oBAAoB;AAAA,IAC/C;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,eAAqB;AACnB,SAAK,MAAM,eAAe;AAC1B,SAAK,MAAM,YAAY,oBAAI,KAAK;AAAA,EAClC;AACF;AAKO,SAAS,oBAAoB,cAAkD;AACpF,SAAO,IAAI,cAAc,YAAY;AACvC;","names":[]}