{"version":3,"sources":["../../src/guardrails/index.ts","../../src/models/openrouter.ts","../../src/models/router.ts","../../src/guardrails/pipeline.ts"],"sourcesContent":["/**\r\n * Guardrails module exports\r\n */\r\n\r\nexport * from './pipeline';\r\n\r\n// Individual guardrail checks for advanced usage\r\nexport { safetyCheck, complianceCheck, confidenceCheck, toneCheck, permissionCheck, ensureSourceCitation } from './pipeline';\r\n","/**\r\n * OpenRouter Client\r\n * Unified model access via OpenRouter API\r\n */\r\n\r\nimport type { ModelConfig, TokenUsage } from '../types';\r\n\r\n// ============================================================================\r\n// Configuration\r\n// ============================================================================\r\n\r\nexport interface OpenRouterConfig {\r\n  apiKey: string;\r\n  baseURL?: string;\r\n  timeout?: number;\r\n}\r\n\r\n// ============================================================================\r\n// Available Models on OpenRouter\r\n// ============================================================================\r\n\r\n/**\r\n * Model catalog with OpenRouter model IDs\r\n * Costs are approximate and may change - check openrouter.ai/docs for current pricing\r\n */\r\nexport const OPENROUTER_MODELS: Record<string, ModelConfig> = {\r\n  // ========== PREMIUM MODELS (High quality, higher cost) ==========\r\n\r\n  'anthropic/claude-3.5-sonnet': {\r\n    id: 'anthropic/claude-3.5-sonnet',\r\n    provider: 'openrouter',\r\n    model: 'anthropic/claude-3.5-sonnet',\r\n    costPerMillionTokens: 3.00, // Input, output is ~$15\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  'anthropic/claude-3.5-sonnet:beta': {\r\n    id: 'anthropic/claude-3.5-sonnet:beta',\r\n    provider: 'openrouter',\r\n    model: 'anthropic/claude-3.5-sonnet:beta',\r\n    costPerMillionTokens: 3.00,\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  'openai/gpt-4o': {\r\n    id: 'openai/gpt-4o',\r\n    provider: 'openrouter',\r\n    model: 'openai/gpt-4o',\r\n    costPerMillionTokens: 2.50, // Input, output is ~$10\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  'google/gemini-2.0-flash-exp': {\r\n    id: 'google/gemini-2.0-flash-exp',\r\n    provider: 'openrouter',\r\n    model: 'google/gemini-2.0-flash-exp',\r\n    costPerMillionTokens: 0.075, // Very cheap!\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  'google/gemini-2.5-pro': {\r\n    id: 'google/gemini-2.5-pro',\r\n    provider: 'openrouter',\r\n    model: 'google/gemini-2.5-pro',\r\n    costPerMillionTokens: 1.25,\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  'google/gemini-2.5-flash-thinking-exp': {\r\n    id: 'google/gemini-2.5-flash-thinking-exp',\r\n    provider: 'openrouter',\r\n    model: 'google/gemini-2.5-flash-thinking-exp',\r\n    costPerMillionTokens: 0.10,\r\n    capabilities: {\r\n      vision: false,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  // ========== FAST CHEAP MODELS (Routing, classification) ==========\r\n\r\n  'openai/gpt-4o-mini': {\r\n    id: 'openai/gpt-4o-mini',\r\n    provider: 'openrouter',\r\n    model: 'openai/gpt-4o-mini',\r\n    costPerMillionTokens: 0.15, // Input, output is ~$0.60\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  'deepseek/deepseek-chat': {\r\n    id: 'deepseek/deepseek-chat',\r\n    provider: 'openrouter',\r\n    model: 'deepseek/deepseek-chat',\r\n    costPerMillionTokens: 0.27, // Input, output is ~$1.10\r\n    capabilities: {\r\n      vision: false,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  'deepseek/deepseek-chat-v3-0324': {\r\n    id: 'deepseek/deepseek-chat-v3-0324',\r\n    provider: 'openrouter',\r\n    model: 'deepseek/deepseek-chat-v3-0324',\r\n    costPerMillionTokens: 0.27,\r\n    capabilities: {\r\n      vision: false,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  'deepseek/deepseek-r1': {\r\n    id: 'deepseek/deepseek-r1',\r\n    provider: 'openrouter',\r\n    model: 'deepseek/deepseek-r1',\r\n    costPerMillionTokens: 0.55, // Reasoning model\r\n    capabilities: {\r\n      vision: false,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  // ========== ULTRA-CHEAP MODELS ==========\r\n\r\n  // Note: Free models change frequently - check openrouter.ai for current free options\r\n\r\n  // ========== VISION MODELS ==========\r\n\r\n  'anthropic/claude-3.5-sonnet': {\r\n    id: 'anthropic/claude-3.5-sonnet',\r\n    provider: 'openrouter',\r\n    model: 'anthropic/claude-3.5-sonnet',\r\n    costPerMillionTokens: 3.00,\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  'openai/gpt-4o': {\r\n    id: 'openai/gpt-4o',\r\n    provider: 'openrouter',\r\n    model: 'openai/gpt-4o',\r\n    costPerMillionTokens: 2.50,\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n\r\n  'google/gemini-2.0-flash-exp': {\r\n    id: 'google/gemini-2.0-flash-exp',\r\n    provider: 'openrouter',\r\n    model: 'google/gemini-2.0-flash-exp',\r\n    costPerMillionTokens: 0.075,\r\n    capabilities: {\r\n      vision: true,\r\n      streaming: true,\r\n      jsonMode: false,\r\n    },\r\n  },\r\n\r\n  // ========== REASONING MODELS ==========\r\n\r\n  'deepseek/deepseek-r1': {\r\n    id: 'deepseek/deepseek-r1',\r\n    provider: 'openrouter',\r\n    model: 'deepseek/deepseek-r1',\r\n    costPerMillionTokens: 0.55,\r\n    capabilities: {\r\n      vision: false,\r\n      streaming: true,\r\n      jsonMode: true,\r\n    },\r\n  },\r\n};\r\n\r\n/**\r\n * Model aliases for easy reference\r\n */\r\nexport const MODEL_ALIASES: Record<string, string> = {\r\n  // Primary models\r\n  'premium': 'anthropic/claude-3.5-sonnet',\r\n  'fast': 'openai/gpt-4o-mini',\r\n  'cheap': 'deepseek/deepseek-chat',\r\n\r\n  // Specific model aliases\r\n  'claude': 'anthropic/claude-3.5-sonnet',\r\n  'gpt4': 'openai/gpt-4o',\r\n  'gpt4-mini': 'openai/gpt-4o-mini',\r\n  'gemini': 'google/gemini-2.5-flash-thinking-exp',\r\n  'deepseek': 'deepseek/deepseek-chat',\r\n  'deepseek-r1': 'deepseek/deepseek-r1',\r\n};\r\n\r\n// ============================================================================\r\n// OpenRouter Client Class\r\n// ============================================================================\r\n\r\nexport interface ChatMessage {\r\n  role: 'system' | 'user' | 'assistant';\r\n  content: string;\r\n}\r\n\r\nexport interface ChatOptions {\r\n  model?: string;\r\n  temperature?: number;\r\n  maxTokens?: number;\r\n  topP?: number;\r\n  stream?: boolean;\r\n}\r\n\r\nexport interface ChatResponse {\r\n  content: string;\r\n  model: string;\r\n  usage: {\r\n    promptTokens: number;\r\n    completionTokens: number;\r\n    totalTokens: number;\r\n  };\r\n  finishReason?: string;\r\n}\r\n\r\n/**\r\n * OpenRouter API Client\r\n */\r\nexport class OpenRouterClient {\r\n  private config: OpenRouterConfig;\r\n  private baseURL: string;\r\n\r\n  constructor(config: OpenRouterConfig) {\r\n    this.config = config;\r\n    this.baseURL = config.baseURL || 'https://openrouter.ai/api/v1';\r\n  }\r\n\r\n  /**\r\n   * Send a chat completion request\r\n   */\r\n  async chat(\r\n    messages: ChatMessage[],\r\n    options: ChatOptions = {}\r\n  ): Promise<ChatResponse> {\r\n    const model = options.model || 'anthropic/claude-3.5-sonnet';\r\n\r\n    const requestBody = {\r\n      model,\r\n      messages: messages.map(m => ({\r\n        role: m.role,\r\n        content: m.content,\r\n      })),\r\n      temperature: options.temperature ?? 0.7,\r\n      max_tokens: options.maxTokens ?? 4096,\r\n      top_p: options.topP,\r\n      stream: options.stream ?? false,\r\n    };\r\n\r\n    const response = await fetch(`${this.baseURL}/chat/completions`, {\r\n      method: 'POST',\r\n      headers: {\r\n        'Authorization': `Bearer ${this.config.apiKey}`,\r\n        'Content-Type': 'application/json',\r\n        'HTTP-Referer': typeof window !== 'undefined' ? window.location.href : 'https://schoolgle.co.uk',\r\n        'X-Title': 'Schoolgle Ed',\r\n      },\r\n      body: JSON.stringify(requestBody),\r\n      signal: options.timeout ? AbortSignal.timeout(options.timeout) : undefined,\r\n    });\r\n\r\n    if (!response.ok) {\r\n      const errorText = await response.text();\r\n      throw new OpenRouterError(\r\n        `OpenRouter API error: ${response.status} ${response.statusText}`,\r\n        response.status,\r\n        errorText\r\n      );\r\n    }\r\n\r\n    const data = await response.json();\r\n\r\n    // Extract response\r\n    const choice = data.choices?.[0];\r\n    if (!choice) {\r\n      throw new OpenRouterError('No choices returned from OpenRouter', 500);\r\n    }\r\n\r\n    return {\r\n      content: choice.message?.content || '',\r\n      model: data.model || model,\r\n      usage: {\r\n        promptTokens: data.usage?.prompt_tokens || 0,\r\n        completionTokens: data.usage?.completion_tokens || 0,\r\n        totalTokens: data.usage?.total_tokens || 0,\r\n      },\r\n      finishReason: choice.finish_reason,\r\n    };\r\n  }\r\n\r\n  /**\r\n   * Send a chat completion request with system prompt\r\n   */\r\n  async chatWithSystem(\r\n    systemPrompt: string,\r\n    userMessage: string,\r\n    options: ChatOptions = {}\r\n  ): Promise<ChatResponse> {\r\n    return this.chat(\r\n      [\r\n        { role: 'system', content: systemPrompt },\r\n        { role: 'user', content: userMessage },\r\n      ],\r\n      options\r\n    );\r\n  }\r\n\r\n  /**\r\n   * Stream a chat completion (for future implementation)\r\n   */\r\n  async *chatStream(\r\n    messages: ChatMessage[],\r\n    options: ChatOptions = {}\r\n  ): AsyncGenerator<string, void, unknown> {\r\n    const model = options.model || 'anthropic/claude-3.5-sonnet';\r\n\r\n    const requestBody = {\r\n      model,\r\n      messages: messages.map(m => ({\r\n        role: m.role,\r\n        content: m.content,\r\n      })),\r\n      temperature: options.temperature ?? 0.7,\r\n      max_tokens: options.maxTokens ?? 4096,\r\n      stream: true,\r\n    };\r\n\r\n    const response = await fetch(`${this.baseURL}/chat/completions`, {\r\n      method: 'POST',\r\n      headers: {\r\n        'Authorization': `Bearer ${this.config.apiKey}`,\r\n        'Content-Type': 'application/json',\r\n        'HTTP-Referer': 'https://schoolgle.co.uk',\r\n        'X-Title': 'Schoolgle Ed',\r\n      },\r\n      body: JSON.stringify(requestBody),\r\n    });\r\n\r\n    if (!response.ok) {\r\n      throw new OpenRouterError(\r\n        `OpenRouter API error: ${response.status} ${response.statusText}`,\r\n        response.status\r\n      );\r\n    }\r\n\r\n    // Stream parsing\r\n    const reader = response.body?.getReader();\r\n    if (!reader) throw new OpenRouterError('No response body', 500);\r\n\r\n    const decoder = new TextDecoder();\r\n\r\n    try {\r\n      while (true) {\r\n        const { done, value } = await reader.read();\r\n        if (done) break;\r\n\r\n        const chunk = decoder.decode(value);\r\n        const lines = chunk.split('\\n').filter(line => line.trim());\r\n\r\n        for (const line of lines) {\r\n          if (line.startsWith('data: ')) {\r\n            const data = line.slice(6);\r\n            if (data === '[DONE]') return;\r\n\r\n            try {\r\n              const parsed = JSON.parse(data);\r\n              const content = parsed.choices?.[0]?.delta?.content;\r\n              if (content) yield content;\r\n            } catch {\r\n              // Skip invalid JSON\r\n            }\r\n          }\r\n        }\r\n      }\r\n    } finally {\r\n      reader.releaseLock();\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Get model info\r\n   */\r\n  getModel(modelIdOrAlias: string): ModelConfig | undefined {\r\n    // Resolve alias\r\n    const modelId = MODEL_ALIASES[modelIdOrAlias] || modelIdOrAlias;\r\n    return OPENROUTER_MODELS[modelId];\r\n  }\r\n\r\n  /**\r\n   * Get all available models\r\n   */\r\n  getAllModels(): Record<string, ModelConfig> {\r\n    return { ...OPENROUTER_MODELS };\r\n  }\r\n}\r\n\r\n// ============================================================================\r\n// Error Class\r\n// ============================================================================\r\n\r\nexport class OpenRouterError extends Error {\r\n  constructor(\r\n    message: string,\r\n    public statusCode: number,\r\n    public responseText?: string\r\n  ) {\r\n    super(message);\r\n    this.name = 'OpenRouterError';\r\n  }\r\n}\r\n\r\n// ============================================================================\r\n// Utility Functions\r\n// ============================================================================\r\n\r\n/**\r\n * Create OpenRouter client from environment\r\n */\r\nexport function createOpenRouterClient(): OpenRouterClient {\r\n  const apiKey = process.env.OPENROUTER_API_KEY || '';\r\n\r\n  if (!apiKey) {\r\n    throw new Error('OPENROUTER_API_KEY environment variable is not set');\r\n  }\r\n\r\n  return new OpenRouterClient({\r\n    apiKey,\r\n    timeout: 30000, // 30 second default\r\n  });\r\n}\r\n\r\n/**\r\n * Calculate token cost\r\n */\r\nexport function calculateTokenCost(\r\n  modelId: string,\r\n  inputTokens: number,\r\n  outputTokens: number\r\n): number {\r\n  const model = OPENROUTER_MODELS[modelId];\r\n  if (!model) return 0;\r\n\r\n  // Note: OpenRouter pricing can vary by provider\r\n  // This is an approximation using the base cost per million tokens\r\n  const inputCost = (inputTokens / 1_000_000) * model.costPerMillionTokens;\r\n  const outputCost = (outputTokens / 1_000_000) * (model.costPerMillionTokens * 3); // Rough estimate\r\n\r\n  return inputCost + outputCost;\r\n}\r\n","/**\r\n * Model Router\r\n * Selects the best model for each task using OpenRouter\r\n */\r\n\r\nimport type { ModelConfig, TaskType, AppContext } from '../types';\r\nimport {\r\n  OPENROUTER_MODELS,\r\n  MODEL_ALIASES,\r\n  createOpenRouterClient,\r\n  calculateTokenCost as calculateORCost,\r\n  type ChatMessage,\r\n  type ChatOptions,\r\n  type ChatResponse,\r\n} from './openrouter';\r\n\r\n// ============================================================================\r\n// Task-to-Model Mapping\r\n// ============================================================================\r\n\r\n/**\r\n * Default model selection by task type\r\n * Ordered by preference (first is optimal, last is fallback)\r\n */\r\nconst TASK_MODEL_MAP: Record<TaskType, string[]> = {\r\n  // Fast/cheap for routing\r\n  'intent-classification': ['openai/gpt-4o-mini', 'google/gemini-2.0-flash-exp', 'deepseek/deepseek-chat'],\r\n  'work-focus-check': ['openai/gpt-4o-mini', 'google/gemini-2.0-flash-exp'],\r\n\r\n  // High quality for specialist responses\r\n  'specialist-response': ['anthropic/claude-3.5-sonnet', 'deepseek/deepseek-chat', 'openai/gpt-4o'],\r\n  'perspective-generation': ['deepseek/deepseek-chat', 'openai/gpt-4o-mini', 'google/gemini-2.0-flash-exp'],\r\n  'synthesis': ['anthropic/claude-3.5-sonnet', 'deepseek/deepseek-chat'],\r\n\r\n  // Vision needed\r\n  'ui-analysis': ['anthropic/claude-3.5-sonnet', 'openai/gpt-4o', 'google/gemini-2.5-pro'],\r\n\r\n  // Fast/cheap for actions\r\n  'action-planning': ['openai/gpt-4o-mini', 'google/gemini-2.0-flash-exp'],\r\n};\r\n\r\n/**\r\n * Plan-based model constraints\r\n */\r\nconst PLAN_MODEL_CONSTRAINTS: Record<string, string[]> = {\r\n  'free': ['openai/gpt-4o-mini', 'google/gemini-2.0-flash-exp', 'deepseek/deepseek-chat'],\r\n  'schools': ['anthropic/claude-3.5-sonnet', 'deepseek/deepseek-chat', 'openai/gpt-4o', 'google/gemini-2.0-flash-exp'],\r\n  'trusts': ['anthropic/claude-3.5-sonnet', 'deepseek/deepseek-r1', 'openai/gpt-4o'],\r\n};\r\n\r\n// ============================================================================\r\n// Model Router\r\n// ============================================================================\r\n\r\n/**\r\n * Model Router class\r\n */\r\nexport class ModelRouter {\r\n  private client: ReturnType<typeof createOpenRouterClient>;\r\n\r\n  constructor() {\r\n    this.client = createOpenRouterClient();\r\n  }\r\n\r\n  /**\r\n   * Select the best model for a given task based on context\r\n   */\r\n  selectModel(task: TaskType, context: AppContext): ModelConfig {\r\n    const availableModels = TASK_MODEL_MAP[task] || TASK_MODEL_MAP['specialist-response'];\r\n    const { plan, creditsRemaining } = context.subscription;\r\n\r\n    // Filter models by plan\r\n    const planModels = PLAN_MODEL_CONSTRAINTS[plan] || availableModels;\r\n    const eligibleModels = availableModels.filter(m => planModels.includes(m));\r\n\r\n    // If low credits, use cheapest option\r\n    if (creditsRemaining < 1000) {\r\n      return this.getCheapestModel(eligibleModels);\r\n    }\r\n\r\n    // Otherwise use optimal (first) model\r\n    const modelId = eligibleModels[0];\r\n    const model = OPENROUTER_MODELS[modelId];\r\n\r\n    if (!model) {\r\n      throw new Error(`Model not found: ${modelId}`);\r\n    }\r\n\r\n    return model;\r\n  }\r\n\r\n  /**\r\n   * Send chat completion request\r\n   */\r\n  async chat(\r\n    systemPrompt: string,\r\n    userMessage: string,\r\n    options: ChatOptions = {}\r\n  ): Promise<ChatResponse> {\r\n    return this.client.chatWithSystem(systemPrompt, userMessage, options);\r\n  }\r\n\r\n  /**\r\n   * Send chat completion with message array\r\n   */\r\n  async chatMessages(\r\n    messages: ChatMessage[],\r\n    options: ChatOptions = {}\r\n  ): Promise<ChatResponse> {\r\n    return this.client.chat(messages, options);\r\n  }\r\n\r\n  /**\r\n   * Stream chat completion (for future use)\r\n   */\r\n  async *chatStream(\r\n    messages: ChatMessage[],\r\n    options: ChatOptions = {}\r\n  ): AsyncGenerator<string> {\r\n    yield* this.client.chatStream(messages, options);\r\n  }\r\n\r\n  /**\r\n   * Get cheapest model from list\r\n   */\r\n  private getCheapestModel(modelIds: string[]): ModelConfig {\r\n    let cheapest = OPENROUTER_MODELS[modelIds[0]];\r\n    let lowestCost = cheapest?.costPerMillionTokens || Infinity;\r\n\r\n    for (const modelId of modelIds) {\r\n      const model = OPENROUTER_MODELS[modelId];\r\n      if (model && model.costPerMillionTokens < lowestCost) {\r\n        cheapest = model;\r\n        lowestCost = model.costPerMillionTokens;\r\n      }\r\n    }\r\n\r\n    return cheapest || OPENROUTER_MODELS['openai/gpt-4o-mini'];\r\n  }\r\n\r\n  /**\r\n   * Get model by ID or alias\r\n   */\r\n  getModel(idOrAlias: string): ModelConfig | undefined {\r\n    const modelId = MODEL_ALIASES[idOrAlias] || idOrAlias;\r\n    return OPENROUTER_MODELS[modelId];\r\n  }\r\n\r\n  /**\r\n   * Get all available models\r\n   */\r\n  getAllModels(): Record<string, ModelConfig> {\r\n    return { ...OPENROUTER_MODELS };\r\n  }\r\n}\r\n\r\n// Singleton instance\r\nlet routerInstance: ModelRouter | null = null;\r\n\r\n/**\r\n * Get or create model router instance\r\n */\r\nexport function getModelRouter(): ModelRouter {\r\n  if (!routerInstance) {\r\n    routerInstance = new ModelRouter();\r\n  }\r\n  return routerInstance;\r\n}\r\n\r\n// ============================================================================\r\n// Legacy Compatibility Functions\r\n// ============================================================================\r\n\r\n/**\r\n * Select model for task (legacy function signature)\r\n */\r\nexport async function selectModel(\r\n  task: TaskType,\r\n  context: AppContext\r\n): Promise<ModelConfig> {\r\n  const router = getModelRouter();\r\n  return router.selectModel(task, context);\r\n}\r\n\r\n/**\r\n * Check credits (simplified)\r\n */\r\nexport async function checkCredits(subscription: { creditsRemaining: number }): Promise<{\r\n  sufficient: boolean;\r\n  estimatedCost: number;\r\n}> {\r\n  // Estimate for typical query\r\n  const estimatedTokens = 1000;\r\n  const model = OPENROUTER_MODELS['google/gemini-2.0-flash-exp'];\r\n  const estimatedCost = (estimatedTokens / 1_000_000) * model.costPerMillionTokens;\r\n\r\n  return {\r\n    sufficient: subscription.creditsRemaining > estimatedCost,\r\n    estimatedCost,\r\n  };\r\n}\r\n\r\n/**\r\n * Calculate cost\r\n */\r\nexport function calculateCost(\r\n  modelId: string,\r\n  inputTokens: number,\r\n  outputTokens: number\r\n): number {\r\n  return calculateORCost(modelId, inputTokens, outputTokens);\r\n}\r\n\r\n/**\r\n * Get model by ID\r\n */\r\nexport function getModel(id: string): ModelConfig | undefined {\r\n  const router = getModelRouter();\r\n  return router.getModel(id);\r\n}\r\n\r\n/**\r\n * Get all models\r\n */\r\nexport function getAllModels(): Record<string, ModelConfig> {\r\n  const router = getModelRouter();\r\n  return router.getAllModels();\r\n}\r\n","/**\r\n * Guardrails Pipeline\r\n * Applies all guardrails to responses before returning to user\r\n */\r\n\r\nimport type { GuardrailResult, AppContext } from '../types';\r\nimport { getModelRouter } from '../models';\r\n\r\n// ============================================================================\r\n// Guardrail Result Types\r\n// ============================================================================\r\n\r\nexport interface GuardrailCheckResult {\r\n  passed: boolean;\r\n  confidence: number; // 0-1\r\n  reason?: string;\r\n  suggestion?: string;\r\n}\r\n\r\n// ============================================================================\r\n// Safety Check\r\n// ============================================================================\r\n\r\n/**\r\n * Safety check patterns - potentially harmful advice indicators\r\n */\r\nconst HARMFUL_PATTERNS = [\r\n  /ignore.*safety/gi,\r\n  /skip.*check/gi,\r\n  /don't.*worry.*about/gi,\r\n  /not.*necessary.*to.*report/gi,\r\n  /just.*ignore.*it/gi,\r\n  /no.*need.*to.*tell.*anyone/gi,\r\n  /keep.*it.*secret.*from.*hse/gi,\r\n  /don't.*bother.*reporting/gi,\r\n  /safety.*rules.*don't.*apply/gi,\r\n  /you.*can.*skip.*this/gi,\r\n];\r\n\r\n/**\r\n * Safety check prompt for LLM-based evaluation\r\n */\r\nconst SAFETY_CHECK_PROMPT = `You are a SAFETY REVIEWER for a school compliance AI.\r\n\r\nYour role is to check if a response contains ANY advice that could:\r\n- Endanger students, staff, or visitors\r\n- Violate health and safety laws\r\n- Lead to non-compliance with statutory requirements\r\n- Compromise safeguarding\r\n\r\nEvaluate the response and respond with ONLY:\r\n- \"PASS\" if the response is safe\r\n- \"FAIL: [reason]\" if it contains potentially harmful advice\r\n\r\nBe cautious - if in doubt, FAIL.`;\r\n\r\n/**\r\n * Check if response contains harmful advice\r\n */\r\nexport async function safetyCheck(\r\n  response: string,\r\n  context?: AppContext\r\n): Promise<GuardrailCheckResult> {\r\n  // Fast pattern-based check first\r\n  for (const pattern of HARMFUL_PATTERNS) {\r\n    if (pattern.test(response)) {\r\n      return {\r\n        passed: false,\r\n        confidence: 0.9,\r\n        reason: `Response may contain unsafe advice (matched pattern: ${pattern.source})`,\r\n        suggestion: 'Please review this guidance for safety concerns before following it.',\r\n      };\r\n    }\r\n  }\r\n\r\n  // LLM-based deep check for ambiguous cases\r\n  try {\r\n    const router = getModelRouter();\r\n    const llmCheck = await router.chat(\r\n      SAFETY_CHECK_PROMPT,\r\n      `**Response to check:**\\n\\n${response}`,\r\n      {\r\n        model: 'openai/gpt-4o-mini',\r\n        temperature: 0.1,\r\n        maxTokens: 50,\r\n      }\r\n    );\r\n\r\n    const result = llmCheck.content.trim().toUpperCase();\r\n\r\n    if (result.startsWith('FAIL')) {\r\n      return {\r\n        passed: false,\r\n        confidence: 0.8,\r\n        reason: result.substring(5).trim() || 'LLM safety check failed',\r\n        suggestion: 'This response may need review. Please verify guidance with official sources.',\r\n      };\r\n    }\r\n\r\n    return { passed: true, confidence: 0.9 };\r\n  } catch {\r\n    // If LLM check fails, assume safe (pattern check already passed)\r\n    return { passed: true, confidence: 0.7 };\r\n  }\r\n}\r\n\r\n// ============================================================================\r\n// Compliance Check\r\n// ============================================================================\r\n\r\n/**\r\n * Compliance uncertainty indicators\r\n */\r\nconst COMPLIANCE_UNCERTAINTY = [\r\n  /may have changed/gi,\r\n  /check.*current.*guidance/gi,\r\n  /not.*verified.*recently/gi,\r\n  /guidance.*may.*vary/gi,\r\n  /recommend.*verification/gi,\r\n  /as far as I know/gi,\r\n  /to the best of my knowledge/gi,\r\n];\r\n\r\n/**\r\n * Compliance check prompt for LLM-based evaluation\r\n */\r\nconst COMPLIANCE_CHECK_PROMPT = `You are a COMPLIANCE REVIEWER for UK schools.\r\n\r\nCheck if the response contains current, accurate statutory guidance. UK schools must follow:\r\n- HSE regulations (RIDDOR, fire safety, legionella, etc.)\r\n- DfE guidance\r\n- Ofsted requirements\r\n- Current legislation (2024-2025)\r\n\r\nRespond with ONLY:\r\n- \"PASS\" if guidance appears current\r\n- \"REVIEW: [reason]\" if guidance may be outdated or needs verification`;\r\n\r\n/**\r\n * Check if guidance is compliant and current\r\n */\r\nexport async function complianceCheck(\r\n  response: string,\r\n  context?: AppContext\r\n): Promise<GuardrailCheckResult> {\r\n  // Pattern-based check for uncertainty indicators\r\n  for (const pattern of COMPLIANCE_UNCERTAINTY) {\r\n    if (pattern.test(response)) {\r\n      return {\r\n        passed: true, // Still pass, but with warning\r\n        confidence: 0.6,\r\n        reason: 'Response indicates guidance may need verification',\r\n        suggestion: 'Please verify this guidance is current before acting on it.',\r\n      };\r\n    }\r\n  }\r\n\r\n  // Check if response has source citation (good sign for compliance)\r\n  const hasSource = response.toLowerCase().includes('source:') ||\r\n                    response.toLowerCase().includes('source:') ||\r\n                    response.toLowerCase().includes('hse.gov.uk') ||\r\n                    response.toLowerCase().includes('gov.uk');\r\n\r\n  if (!hasSource) {\r\n    return {\r\n      passed: true,\r\n      confidence: 0.7,\r\n      reason: 'No source citation provided',\r\n      suggestion: 'Guidance would be more reliable with source citation.',\r\n    };\r\n  }\r\n\r\n  return { passed: true, confidence: 0.9 };\r\n}\r\n\r\n// ============================================================================\r\n// Confidence Check\r\n// ============================================================================\r\n\r\n/**\r\n * Check knowledge confidence based on response characteristics\r\n */\r\nexport async function confidenceCheck(\r\n  response: string,\r\n  context?: AppContext\r\n): Promise<GuardrailCheckResult & { confidence: 'HIGH' | 'MEDIUM' | 'LOW' }> {\r\n  let score = 0;\r\n\r\n  // Has source citation (+2)\r\n  if (response.toLowerCase().includes('source:') ||\r\n      response.toLowerCase().includes('hse') ||\r\n      response.toLowerCase().includes('gov.uk')) {\r\n    score += 2;\r\n  }\r\n\r\n  // Has date/freshness info (+1)\r\n  if (response.toLowerCase().includes('last updated') ||\r\n      response.toLowerCase().includes('2024') ||\r\n      response.toLowerCase().includes('2025')) {\r\n    score += 1;\r\n  }\r\n\r\n  // Has uncertainty indicators (-2)\r\n  for (const pattern of COMPLIANCE_UNCERTAINTY) {\r\n    if (pattern.test(response)) {\r\n      score -= 2;\r\n      break;\r\n    }\r\n  }\r\n\r\n  // Specific and actionable (+1)\r\n  if (response.includes('###') || response.includes('1.') || response.includes('-')) {\r\n    score += 1;\r\n  }\r\n\r\n  // Very brief responses are lower confidence\r\n  if (response.length < 200) {\r\n    score -= 1;\r\n  }\r\n\r\n  // Determine confidence level\r\n  let confidence: 'HIGH' | 'MEDIUM' | 'LOW';\r\n  if (score >= 3) {\r\n    confidence = 'HIGH';\r\n  } else if (score >= 1) {\r\n    confidence = 'MEDIUM';\r\n  } else {\r\n    confidence = 'LOW';\r\n  }\r\n\r\n  return {\r\n    passed: true, // Confidence check never blocks\r\n    confidence,\r\n    reason: `Confidence score: ${score}/5`,\r\n    suggestion: confidence === 'LOW' ? 'Please verify this guidance for critical matters.' : undefined,\r\n  };\r\n}\r\n\r\n// ============================================================================\r\n// Tone Check\r\n// ============================================================================\r\n\r\n/**\r\n * Tone issues to detect\r\n */\r\nconst TONE_ISSUES = [\r\n  { pattern: /stupid|idiotic|dumb|idiot|moron/gi, issue: 'Inappropriate language' },\r\n  { pattern: /whatever|doesn't matter|who cares/gi, issue: 'Dismissive tone' },\r\n  { pattern: /i don't care|not my problem/gi, issue: 'Unhelpful attitude' },\r\n  { pattern: /obviously|clearly.*you should.*know/gi, issue: 'Condescending tone' },\r\n  { pattern: /just.*do.*it|stop.*asking/gi, issue: 'Impatient tone' },\r\n];\r\n\r\n/**\r\n * Tone check prompt for LLM-based evaluation\r\n */\r\nconst TONE_CHECK_PROMPT = `You are a TONE REVIEWER for Schoolgle, a helpful school assistant.\r\n\r\nEd's tone should be:\r\n- Warm and supportive\r\n- Professional and respectful\r\n- Clear and concise\r\n- Empathetic to busy school staff\r\n\r\nCheck if the response has appropriate tone. Respond with ONLY:\r\n- \"PASS\" if tone is appropriate\r\n- \"FAIL: [reason]\" if tone is inappropriate (too informal, rude, dismissive, etc.)`;\r\n\r\n/**\r\n * Check if response has appropriate tone\r\n */\r\nexport async function toneCheck(\r\n  response: string,\r\n  context?: AppContext\r\n): Promise<GuardrailCheckResult> {\r\n  // Fast pattern-based check\r\n  for (const { pattern, issue } of TONE_ISSUES) {\r\n    if (pattern.test(response)) {\r\n      return {\r\n        passed: false,\r\n        confidence: 0.9,\r\n        reason: `Tone issue: ${issue}`,\r\n        suggestion: 'The response should be rephrased in a more professional, supportive manner.',\r\n      };\r\n    }\r\n  }\r\n\r\n  // LLM-based tone check for subtler issues\r\n  try {\r\n    const router = getModelRouter();\r\n    const llmCheck = await router.chat(\r\n      TONE_CHECK_PROMPT,\r\n      `**Response to check:**\\n\\n${response}`,\r\n      {\r\n        model: 'openai/gpt-4o-mini',\r\n        temperature: 0.1,\r\n        maxTokens: 50,\r\n      }\r\n    );\r\n\r\n    const result = llmCheck.content.trim().toUpperCase();\r\n\r\n    if (result.startsWith('FAIL')) {\r\n      return {\r\n        passed: false,\r\n        confidence: 0.7,\r\n        reason: result.substring(5).trim() || 'Tone check failed',\r\n        suggestion: 'Response tone should be adjusted to be more supportive and professional.',\r\n      };\r\n    }\r\n\r\n    return { passed: true, confidence: 0.9 };\r\n  } catch {\r\n    return { passed: true, confidence: 0.7 };\r\n  }\r\n}\r\n\r\n// ============================================================================\r\n// Permission Check\r\n// ============================================================================\r\n\r\n/**\r\n * Check if user has permission for this information\r\n */\r\nexport async function permissionCheck(\r\n  response: string,\r\n  context: AppContext\r\n): Promise<GuardrailCheckResult> {\r\n  const { userRole, subscription, activeApp } = context;\r\n\r\n  // Viewer role gets limited access\r\n  if (userRole === 'viewer') {\r\n    // Check for restricted content\r\n    const restrictedKeywords = [\r\n      'salary details',\r\n      'contract details',\r\n      'confidential information',\r\n      'sensitive information',\r\n      'staff personal data',\r\n    ];\r\n\r\n    for (const keyword of restrictedKeywords) {\r\n      if (response.toLowerCase().includes(keyword)) {\r\n        return {\r\n          passed: false,\r\n          confidence: 0.95,\r\n          reason: 'Content requires higher permissions',\r\n          suggestion: 'You do not have permission to view this information. Please contact your administrator.',\r\n        };\r\n      }\r\n    }\r\n  }\r\n\r\n  // Check feature access based on subscription\r\n  if (subscription.plan === 'free') {\r\n    const paidFeatures = ['estates', 'hr', 'send', 'data', 'curriculum', 'procurement', 'governance'];\r\n    // This would be set by the agent-router earlier, but we double-check\r\n    // If response contains detailed specialist advice, flag it\r\n  }\r\n\r\n  return { passed: true, confidence: 1.0 };\r\n}\r\n\r\n// ============================================================================\r\n// Source Requirement\r\n// ============================================================================\r\n\r\n/**\r\n * Ensure source citation is included\r\n */\r\nexport function ensureSourceCitation(\r\n  response: string,\r\n  domain?: string\r\n): string {\r\n  // Check if source already cited\r\n  const hasSource = response.toLowerCase().includes('source:') ||\r\n                    response.toLowerCase().includes('source:') ||\r\n                    response.toLowerCase().includes('**source**') ||\r\n                    response.toLowerCase().includes('*source*');\r\n\r\n  if (hasSource) {\r\n    return response;\r\n  }\r\n\r\n  // Add generic source citation\r\n  const domainSources: Record<string, string> = {\r\n    estates: 'HSE',\r\n    hr: 'ACAS / Gov.uk',\r\n    send: 'SEND Code of Practice',\r\n    data: 'DfE',\r\n    curriculum: 'DfE / Ofsted',\r\n    'it-tech': 'DfE / vendor documentation',\r\n    procurement: 'CIPS / Gov.uk',\r\n    governance: 'DfE / NGA',\r\n    communications: 'CIPR / Gov.uk',\r\n  };\r\n\r\n  const sourceName = domain ? domainSources[domain] || 'Schoolgle Knowledge Base' : 'Schoolgle Knowledge Base';\r\n\r\n  return `${response}\r\n\r\n---\r\n\r\n*Source: ${sourceName} | Confidence: Medium | Please verify for critical matters*`;\r\n}\r\n\r\n// ============================================================================\r\n// Full Pipeline\r\n// ============================================================================\r\n\r\n/**\r\n * Apply all guardrails to a response\r\n */\r\nexport async function applyGuardrails(\r\n  response: string,\r\n  context: AppContext,\r\n  domain?: string\r\n): Promise<GuardrailResult> {\r\n  // Run all checks in parallel where possible\r\n  const [\r\n    safety,\r\n    compliance,\r\n    tone,\r\n    permission,\r\n  ] = await Promise.all([\r\n    safetyCheck(response, context),\r\n    complianceCheck(response, context),\r\n    toneCheck(response, context),\r\n    permissionCheck(response, context),\r\n  ]);\r\n\r\n  // Confidence check is synchronous\r\n  const confidenceResult = await confidenceCheck(response, context);\r\n\r\n  // 1. Safety check - most critical, fail fast\r\n  if (!safety.passed && safety.confidence > 0.7) {\r\n    return {\r\n      passed: false,\r\n      requiresHuman: true,\r\n      reason: safety.reason,\r\n      response: formatWithWarning(response, SAFETY_WARNING, safety.suggestion),\r\n    };\r\n  }\r\n\r\n  // 2. Tone check - must be professional\r\n  if (!tone.passed && tone.confidence > 0.7) {\r\n    return {\r\n      passed: true,\r\n      warning: 'Tone adjustment recommended',\r\n      response: await adjustTone(response, tone.reason),\r\n    };\r\n  }\r\n\r\n  // 3. Permission check - access control\r\n  if (!permission.passed) {\r\n    return {\r\n      passed: false,\r\n      response: permission.suggestion || \"I don't have access to that information. Please contact your administrator.\",\r\n      reason: permission.reason,\r\n    };\r\n  }\r\n\r\n  // 4. Build final response with warnings and sources\r\n  let finalResponse = response;\r\n  const warnings: string[] = [];\r\n\r\n  // Add compliance warning if needed\r\n  if (compliance.reason && compliance.confidence < 0.7) {\r\n    warnings.push(compliance.suggestion || 'Please verify this guidance is current.');\r\n  }\r\n\r\n  // Add confidence warning if low\r\n  if (confidenceResult.confidence === 'LOW') {\r\n    warnings.push('Low confidence - please verify for critical matters.');\r\n  }\r\n\r\n  // 5. Ensure source citation\r\n  finalResponse = ensureSourceCitation(finalResponse, domain);\r\n\r\n  // 6. Add warnings if present\r\n  if (warnings.length > 0) {\r\n    finalResponse = `${finalResponse}\\n\\n⚠️ **Note:** ${warnings.join(' ')}`;\r\n  }\r\n\r\n  return {\r\n    passed: true,\r\n    response: finalResponse,\r\n    warning: warnings.length > 0 ? warnings.join(' ') : undefined,\r\n    metadata: {\r\n      safetyPassed: safety.passed,\r\n      confidenceLevel: confidenceResult.confidence,\r\n      hasSource: finalResponse.toLowerCase().includes('source'),\r\n    },\r\n  };\r\n}\r\n\r\n// ============================================================================\r\n// Warning Messages\r\n// ============================================================================\r\n\r\nconst SAFETY_WARNING = `\r\n⚠️ **Safety Warning:** This response has been flagged for potential safety concerns.\r\n\r\n**Please do not act on this advice without:**\r\n1. Verifying with official sources (HSE, DfE, etc.)\r\n2. Consulting with appropriate qualified staff\r\n3. Checking your school's specific policies\r\n\r\nIf this is a safety-critical matter, please seek professional advice immediately.`;\r\n\r\n/**\r\n * Format response with warning\r\n */\r\nfunction formatWithWarning(\r\n  response: string,\r\n  warning: string,\r\n  suggestion?: string\r\n): string {\r\n  return `${response}\r\n\r\n${warning}\r\n\r\n${suggestion ? `**Suggestion:** ${suggestion}` : ''}`;\r\n}\r\n\r\n/**\r\n * Adjust tone of response (placeholder - would use LLM in production)\r\n */\r\nasync function adjustTone(response: string, reason?: string): Promise<string> {\r\n  // In production, would use LLM to rephrase\r\n  // For now, return as-is with note\r\n  return `${response}\r\n\r\n*(Note: This response may need tone adjustment - ${reason || 'be more professional'})*`;\r\n}\r\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;;ACyBO,IAAM,oBAAiD;AAAA;AAAA,EAG5D,+BAA+B;AAAA,IAC7B,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,oCAAoC;AAAA,IAClC,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,iBAAiB;AAAA,IACf,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,+BAA+B;AAAA,IAC7B,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,yBAAyB;AAAA,IACvB,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,wCAAwC;AAAA,IACtC,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA;AAAA,EAIA,sBAAsB;AAAA,IACpB,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,0BAA0B;AAAA,IACxB,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,kCAAkC;AAAA,IAChC,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,wBAAwB;AAAA,IACtB,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAQA,+BAA+B;AAAA,IAC7B,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,iBAAiB;AAAA,IACf,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA,EAEA,+BAA+B;AAAA,IAC7B,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AAAA;AAAA,EAIA,wBAAwB;AAAA,IACtB,IAAI;AAAA,IACJ,UAAU;AAAA,IACV,OAAO;AAAA,IACP,sBAAsB;AAAA,IACtB,cAAc;AAAA,MACZ,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,UAAU;AAAA,IACZ;AAAA,EACF;AACF;AAKO,IAAM,gBAAwC;AAAA;AAAA,EAEnD,WAAW;AAAA,EACX,QAAQ;AAAA,EACR,SAAS;AAAA;AAAA,EAGT,UAAU;AAAA,EACV,QAAQ;AAAA,EACR,aAAa;AAAA,EACb,UAAU;AAAA,EACV,YAAY;AAAA,EACZ,eAAe;AACjB;AAiCO,IAAM,mBAAN,MAAuB;AAAA,EAI5B,YAAY,QAA0B;AACpC,SAAK,SAAS;AACd,SAAK,UAAU,OAAO,WAAW;AAAA,EACnC;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,KACJ,UACA,UAAuB,CAAC,GACD;AA/Q3B;AAgRI,UAAM,QAAQ,QAAQ,SAAS;AAE/B,UAAM,cAAc;AAAA,MAClB;AAAA,MACA,UAAU,SAAS,IAAI,QAAM;AAAA,QAC3B,MAAM,EAAE;AAAA,QACR,SAAS,EAAE;AAAA,MACb,EAAE;AAAA,MACF,cAAa,aAAQ,gBAAR,YAAuB;AAAA,MACpC,aAAY,aAAQ,cAAR,YAAqB;AAAA,MACjC,OAAO,QAAQ;AAAA,MACf,SAAQ,aAAQ,WAAR,YAAkB;AAAA,IAC5B;AAEA,UAAM,WAAW,MAAM,MAAM,GAAG,KAAK,OAAO,qBAAqB;AAAA,MAC/D,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,iBAAiB,UAAU,KAAK,OAAO,MAAM;AAAA,QAC7C,gBAAgB;AAAA,QAChB,gBAAgB,OAAO,WAAW,cAAc,OAAO,SAAS,OAAO;AAAA,QACvE,WAAW;AAAA,MACb;AAAA,MACA,MAAM,KAAK,UAAU,WAAW;AAAA,MAChC,QAAQ,QAAQ,UAAU,YAAY,QAAQ,QAAQ,OAAO,IAAI;AAAA,IACnE,CAAC;AAED,QAAI,CAAC,SAAS,IAAI;AAChB,YAAM,YAAY,MAAM,SAAS,KAAK;AACtC,YAAM,IAAI;AAAA,QACR,yBAAyB,SAAS,MAAM,IAAI,SAAS,UAAU;AAAA,QAC/D,SAAS;AAAA,QACT;AAAA,MACF;AAAA,IACF;AAEA,UAAM,OAAO,MAAM,SAAS,KAAK;AAGjC,UAAM,UAAS,UAAK,YAAL,mBAAe;AAC9B,QAAI,CAAC,QAAQ;AACX,YAAM,IAAI,gBAAgB,uCAAuC,GAAG;AAAA,IACtE;AAEA,WAAO;AAAA,MACL,WAAS,YAAO,YAAP,mBAAgB,YAAW;AAAA,MACpC,OAAO,KAAK,SAAS;AAAA,MACrB,OAAO;AAAA,QACL,gBAAc,UAAK,UAAL,mBAAY,kBAAiB;AAAA,QAC3C,oBAAkB,UAAK,UAAL,mBAAY,sBAAqB;AAAA,QACnD,eAAa,UAAK,UAAL,mBAAY,iBAAgB;AAAA,MAC3C;AAAA,MACA,cAAc,OAAO;AAAA,IACvB;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,eACJ,cACA,aACA,UAAuB,CAAC,GACD;AACvB,WAAO,KAAK;AAAA,MACV;AAAA,QACE,EAAE,MAAM,UAAU,SAAS,aAAa;AAAA,QACxC,EAAE,MAAM,QAAQ,SAAS,YAAY;AAAA,MACvC;AAAA,MACA;AAAA,IACF;AAAA,EACF;AAAA;AAAA;AAAA;AAAA,EAKO,WACL,IAEuC;AAAA,wDAFvC,UACA,UAAuB,CAAC,GACe;AA9V3C;AA+VI,YAAM,QAAQ,QAAQ,SAAS;AAE/B,YAAM,cAAc;AAAA,QAClB;AAAA,QACA,UAAU,SAAS,IAAI,QAAM;AAAA,UAC3B,MAAM,EAAE;AAAA,UACR,SAAS,EAAE;AAAA,QACb,EAAE;AAAA,QACF,cAAa,aAAQ,gBAAR,YAAuB;AAAA,QACpC,aAAY,aAAQ,cAAR,YAAqB;AAAA,QACjC,QAAQ;AAAA,MACV;AAEA,YAAM,WAAW,kBAAM,MAAM,GAAG,KAAK,OAAO,qBAAqB;AAAA,QAC/D,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,iBAAiB,UAAU,KAAK,OAAO,MAAM;AAAA,UAC7C,gBAAgB;AAAA,UAChB,gBAAgB;AAAA,UAChB,WAAW;AAAA,QACb;AAAA,QACA,MAAM,KAAK,UAAU,WAAW;AAAA,MAClC,CAAC;AAED,UAAI,CAAC,SAAS,IAAI;AAChB,cAAM,IAAI;AAAA,UACR,yBAAyB,SAAS,MAAM,IAAI,SAAS,UAAU;AAAA,UAC/D,SAAS;AAAA,QACX;AAAA,MACF;AAGA,YAAM,UAAS,cAAS,SAAT,mBAAe;AAC9B,UAAI,CAAC,OAAQ,OAAM,IAAI,gBAAgB,oBAAoB,GAAG;AAE9D,YAAM,UAAU,IAAI,YAAY;AAEhC,UAAI;AACF,eAAO,MAAM;AACX,gBAAM,EAAE,MAAM,MAAM,IAAI,kBAAM,OAAO,KAAK;AAC1C,cAAI,KAAM;AAEV,gBAAM,QAAQ,QAAQ,OAAO,KAAK;AAClC,gBAAM,QAAQ,MAAM,MAAM,IAAI,EAAE,OAAO,UAAQ,KAAK,KAAK,CAAC;AAE1D,qBAAW,QAAQ,OAAO;AACxB,gBAAI,KAAK,WAAW,QAAQ,GAAG;AAC7B,oBAAM,OAAO,KAAK,MAAM,CAAC;AACzB,kBAAI,SAAS,SAAU;AAEvB,kBAAI;AACF,sBAAM,SAAS,KAAK,MAAM,IAAI;AAC9B,sBAAM,WAAU,wBAAO,YAAP,mBAAiB,OAAjB,mBAAqB,UAArB,mBAA4B;AAC5C,oBAAI,QAAS,OAAM;AAAA,cACrB,SAAQ;AAAA,cAER;AAAA,YACF;AAAA,UACF;AAAA,QACF;AAAA,MACF,UAAE;AACA,eAAO,YAAY;AAAA,MACrB;AAAA,IACF;AAAA;AAAA;AAAA;AAAA;AAAA,EAKA,SAAS,gBAAiD;AAExD,UAAM,UAAU,cAAc,cAAc,KAAK;AACjD,WAAO,kBAAkB,OAAO;AAAA,EAClC;AAAA;AAAA;AAAA;AAAA,EAKA,eAA4C;AAC1C,WAAO,mBAAK;AAAA,EACd;AACF;AAMO,IAAM,kBAAN,cAA8B,MAAM;AAAA,EACzC,YACE,SACO,YACA,cACP;AACA,UAAM,OAAO;AAHN;AACA;AAGP,SAAK,OAAO;AAAA,EACd;AACF;AASO,SAAS,yBAA2C;AACzD,QAAM,SAAS,QAAQ,IAAI,sBAAsB;AAEjD,MAAI,CAAC,QAAQ;AACX,UAAM,IAAI,MAAM,oDAAoD;AAAA,EACtE;AAEA,SAAO,IAAI,iBAAiB;AAAA,IAC1B;AAAA,IACA,SAAS;AAAA;AAAA,EACX,CAAC;AACH;;;AC1bA,IAAM,iBAA6C;AAAA;AAAA,EAEjD,yBAAyB,CAAC,sBAAsB,+BAA+B,wBAAwB;AAAA,EACvG,oBAAoB,CAAC,sBAAsB,6BAA6B;AAAA;AAAA,EAGxE,uBAAuB,CAAC,+BAA+B,0BAA0B,eAAe;AAAA,EAChG,0BAA0B,CAAC,0BAA0B,sBAAsB,6BAA6B;AAAA,EACxG,aAAa,CAAC,+BAA+B,wBAAwB;AAAA;AAAA,EAGrE,eAAe,CAAC,+BAA+B,iBAAiB,uBAAuB;AAAA;AAAA,EAGvF,mBAAmB,CAAC,sBAAsB,6BAA6B;AACzE;AAKA,IAAM,yBAAmD;AAAA,EACvD,QAAQ,CAAC,sBAAsB,+BAA+B,wBAAwB;AAAA,EACtF,WAAW,CAAC,+BAA+B,0BAA0B,iBAAiB,6BAA6B;AAAA,EACnH,UAAU,CAAC,+BAA+B,wBAAwB,eAAe;AACnF;AASO,IAAM,cAAN,MAAkB;AAAA,EAGvB,cAAc;AACZ,SAAK,SAAS,uBAAuB;AAAA,EACvC;AAAA;AAAA;AAAA;AAAA,EAKA,YAAY,MAAgB,SAAkC;AAC5D,UAAM,kBAAkB,eAAe,IAAI,KAAK,eAAe,qBAAqB;AACpF,UAAM,EAAE,MAAM,iBAAiB,IAAI,QAAQ;AAG3C,UAAM,aAAa,uBAAuB,IAAI,KAAK;AACnD,UAAM,iBAAiB,gBAAgB,OAAO,OAAK,WAAW,SAAS,CAAC,CAAC;AAGzE,QAAI,mBAAmB,KAAM;AAC3B,aAAO,KAAK,iBAAiB,cAAc;AAAA,IAC7C;AAGA,UAAM,UAAU,eAAe,CAAC;AAChC,UAAM,QAAQ,kBAAkB,OAAO;AAEvC,QAAI,CAAC,OAAO;AACV,YAAM,IAAI,MAAM,oBAAoB,OAAO,EAAE;AAAA,IAC/C;AAEA,WAAO;AAAA,EACT;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,KACJ,cACA,aACA,UAAuB,CAAC,GACD;AACvB,WAAO,KAAK,OAAO,eAAe,cAAc,aAAa,OAAO;AAAA,EACtE;AAAA;AAAA;AAAA;AAAA,EAKA,MAAM,aACJ,UACA,UAAuB,CAAC,GACD;AACvB,WAAO,KAAK,OAAO,KAAK,UAAU,OAAO;AAAA,EAC3C;AAAA;AAAA;AAAA;AAAA,EAKO,WACL,IAEwB;AAAA,wDAFxB,UACA,UAAuB,CAAC,GACA;AACxB,yBAAO,KAAK,OAAO,WAAW,UAAU,OAAO;AAAA,IACjD;AAAA;AAAA;AAAA;AAAA;AAAA,EAKQ,iBAAiB,UAAiC;AACxD,QAAI,WAAW,kBAAkB,SAAS,CAAC,CAAC;AAC5C,QAAI,cAAa,qCAAU,yBAAwB;AAEnD,eAAW,WAAW,UAAU;AAC9B,YAAM,QAAQ,kBAAkB,OAAO;AACvC,UAAI,SAAS,MAAM,uBAAuB,YAAY;AACpD,mBAAW;AACX,qBAAa,MAAM;AAAA,MACrB;AAAA,IACF;AAEA,WAAO,YAAY,kBAAkB,oBAAoB;AAAA,EAC3D;AAAA;AAAA;AAAA;AAAA,EAKA,SAAS,WAA4C;AACnD,UAAM,UAAU,cAAc,SAAS,KAAK;AAC5C,WAAO,kBAAkB,OAAO;AAAA,EAClC;AAAA;AAAA;AAAA;AAAA,EAKA,eAA4C;AAC1C,WAAO,mBAAK;AAAA,EACd;AACF;AAGA,IAAI,iBAAqC;AAKlC,SAAS,iBAA8B;AAC5C,MAAI,CAAC,gBAAgB;AACnB,qBAAiB,IAAI,YAAY;AAAA,EACnC;AACA,SAAO;AACT;;;AC7IA,IAAM,mBAAmB;AAAA,EACvB;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAKA,IAAM,sBAAsB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAiB5B,eAAsB,YACpB,UACA,SAC+B;AAE/B,aAAW,WAAW,kBAAkB;AACtC,QAAI,QAAQ,KAAK,QAAQ,GAAG;AAC1B,aAAO;AAAA,QACL,QAAQ;AAAA,QACR,YAAY;AAAA,QACZ,QAAQ,wDAAwD,QAAQ,MAAM;AAAA,QAC9E,YAAY;AAAA,MACd;AAAA,IACF;AAAA,EACF;AAGA,MAAI;AACF,UAAM,SAAS,eAAe;AAC9B,UAAM,WAAW,MAAM,OAAO;AAAA,MAC5B;AAAA,MACA;AAAA;AAAA,EAA6B,QAAQ;AAAA,MACrC;AAAA,QACE,OAAO;AAAA,QACP,aAAa;AAAA,QACb,WAAW;AAAA,MACb;AAAA,IACF;AAEA,UAAM,SAAS,SAAS,QAAQ,KAAK,EAAE,YAAY;AAEnD,QAAI,OAAO,WAAW,MAAM,GAAG;AAC7B,aAAO;AAAA,QACL,QAAQ;AAAA,QACR,YAAY;AAAA,QACZ,QAAQ,OAAO,UAAU,CAAC,EAAE,KAAK,KAAK;AAAA,QACtC,YAAY;AAAA,MACd;AAAA,IACF;AAEA,WAAO,EAAE,QAAQ,MAAM,YAAY,IAAI;AAAA,EACzC,SAAQ;AAEN,WAAO,EAAE,QAAQ,MAAM,YAAY,IAAI;AAAA,EACzC;AACF;AASA,IAAM,yBAAyB;AAAA,EAC7B;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AACF;AAoBA,eAAsB,gBACpB,UACA,SAC+B;AAE/B,aAAW,WAAW,wBAAwB;AAC5C,QAAI,QAAQ,KAAK,QAAQ,GAAG;AAC1B,aAAO;AAAA,QACL,QAAQ;AAAA;AAAA,QACR,YAAY;AAAA,QACZ,QAAQ;AAAA,QACR,YAAY;AAAA,MACd;AAAA,IACF;AAAA,EACF;AAGA,QAAM,YAAY,SAAS,YAAY,EAAE,SAAS,SAAS,KACzC,SAAS,YAAY,EAAE,SAAS,SAAS,KACzC,SAAS,YAAY,EAAE,SAAS,YAAY,KAC5C,SAAS,YAAY,EAAE,SAAS,QAAQ;AAE1D,MAAI,CAAC,WAAW;AACd,WAAO;AAAA,MACL,QAAQ;AAAA,MACR,YAAY;AAAA,MACZ,QAAQ;AAAA,MACR,YAAY;AAAA,IACd;AAAA,EACF;AAEA,SAAO,EAAE,QAAQ,MAAM,YAAY,IAAI;AACzC;AASA,eAAsB,gBACpB,UACA,SAC2E;AAC3E,MAAI,QAAQ;AAGZ,MAAI,SAAS,YAAY,EAAE,SAAS,SAAS,KACzC,SAAS,YAAY,EAAE,SAAS,KAAK,KACrC,SAAS,YAAY,EAAE,SAAS,QAAQ,GAAG;AAC7C,aAAS;AAAA,EACX;AAGA,MAAI,SAAS,YAAY,EAAE,SAAS,cAAc,KAC9C,SAAS,YAAY,EAAE,SAAS,MAAM,KACtC,SAAS,YAAY,EAAE,SAAS,MAAM,GAAG;AAC3C,aAAS;AAAA,EACX;AAGA,aAAW,WAAW,wBAAwB;AAC5C,QAAI,QAAQ,KAAK,QAAQ,GAAG;AAC1B,eAAS;AACT;AAAA,IACF;AAAA,EACF;AAGA,MAAI,SAAS,SAAS,KAAK,KAAK,SAAS,SAAS,IAAI,KAAK,SAAS,SAAS,GAAG,GAAG;AACjF,aAAS;AAAA,EACX;AAGA,MAAI,SAAS,SAAS,KAAK;AACzB,aAAS;AAAA,EACX;AAGA,MAAI;AACJ,MAAI,SAAS,GAAG;AACd,iBAAa;AAAA,EACf,WAAW,SAAS,GAAG;AACrB,iBAAa;AAAA,EACf,OAAO;AACL,iBAAa;AAAA,EACf;AAEA,SAAO;AAAA,IACL,QAAQ;AAAA;AAAA,IACR;AAAA,IACA,QAAQ,qBAAqB,KAAK;AAAA,IAClC,YAAY,eAAe,QAAQ,sDAAsD;AAAA,EAC3F;AACF;AASA,IAAM,cAAc;AAAA,EAClB,EAAE,SAAS,qCAAqC,OAAO,yBAAyB;AAAA,EAChF,EAAE,SAAS,uCAAuC,OAAO,kBAAkB;AAAA,EAC3E,EAAE,SAAS,iCAAiC,OAAO,qBAAqB;AAAA,EACxE,EAAE,SAAS,yCAAyC,OAAO,qBAAqB;AAAA,EAChF,EAAE,SAAS,+BAA+B,OAAO,iBAAiB;AACpE;AAKA,IAAM,oBAAoB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAe1B,eAAsB,UACpB,UACA,SAC+B;AAE/B,aAAW,EAAE,SAAS,MAAM,KAAK,aAAa;AAC5C,QAAI,QAAQ,KAAK,QAAQ,GAAG;AAC1B,aAAO;AAAA,QACL,QAAQ;AAAA,QACR,YAAY;AAAA,QACZ,QAAQ,eAAe,KAAK;AAAA,QAC5B,YAAY;AAAA,MACd;AAAA,IACF;AAAA,EACF;AAGA,MAAI;AACF,UAAM,SAAS,eAAe;AAC9B,UAAM,WAAW,MAAM,OAAO;AAAA,MAC5B;AAAA,MACA;AAAA;AAAA,EAA6B,QAAQ;AAAA,MACrC;AAAA,QACE,OAAO;AAAA,QACP,aAAa;AAAA,QACb,WAAW;AAAA,MACb;AAAA,IACF;AAEA,UAAM,SAAS,SAAS,QAAQ,KAAK,EAAE,YAAY;AAEnD,QAAI,OAAO,WAAW,MAAM,GAAG;AAC7B,aAAO;AAAA,QACL,QAAQ;AAAA,QACR,YAAY;AAAA,QACZ,QAAQ,OAAO,UAAU,CAAC,EAAE,KAAK,KAAK;AAAA,QACtC,YAAY;AAAA,MACd;AAAA,IACF;AAEA,WAAO,EAAE,QAAQ,MAAM,YAAY,IAAI;AAAA,EACzC,SAAQ;AACN,WAAO,EAAE,QAAQ,MAAM,YAAY,IAAI;AAAA,EACzC;AACF;AASA,eAAsB,gBACpB,UACA,SAC+B;AAC/B,QAAM,EAAE,UAAU,cAAc,UAAU,IAAI;AAG9C,MAAI,aAAa,UAAU;AAEzB,UAAM,qBAAqB;AAAA,MACzB;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAEA,eAAW,WAAW,oBAAoB;AACxC,UAAI,SAAS,YAAY,EAAE,SAAS,OAAO,GAAG;AAC5C,eAAO;AAAA,UACL,QAAQ;AAAA,UACR,YAAY;AAAA,UACZ,QAAQ;AAAA,UACR,YAAY;AAAA,QACd;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAGA,MAAI,aAAa,SAAS,QAAQ;AAChC,UAAM,eAAe,CAAC,WAAW,MAAM,QAAQ,QAAQ,cAAc,eAAe,YAAY;AAAA,EAGlG;AAEA,SAAO,EAAE,QAAQ,MAAM,YAAY,EAAI;AACzC;AASO,SAAS,qBACd,UACA,QACQ;AAER,QAAM,YAAY,SAAS,YAAY,EAAE,SAAS,SAAS,KACzC,SAAS,YAAY,EAAE,SAAS,SAAS,KACzC,SAAS,YAAY,EAAE,SAAS,YAAY,KAC5C,SAAS,YAAY,EAAE,SAAS,UAAU;AAE5D,MAAI,WAAW;AACb,WAAO;AAAA,EACT;AAGA,QAAM,gBAAwC;AAAA,IAC5C,SAAS;AAAA,IACT,IAAI;AAAA,IACJ,MAAM;AAAA,IACN,MAAM;AAAA,IACN,YAAY;AAAA,IACZ,WAAW;AAAA,IACX,aAAa;AAAA,IACb,YAAY;AAAA,IACZ,gBAAgB;AAAA,EAClB;AAEA,QAAM,aAAa,SAAS,cAAc,MAAM,KAAK,6BAA6B;AAElF,SAAO,GAAG,QAAQ;AAAA;AAAA;AAAA;AAAA,WAIT,UAAU;AACrB;AASA,eAAsB,gBACpB,UACA,SACA,QAC0B;AAE1B,QAAM;AAAA,IACJ;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,IAAI,MAAM,QAAQ,IAAI;AAAA,IACpB,YAAY,UAAU,OAAO;AAAA,IAC7B,gBAAgB,UAAU,OAAO;AAAA,IACjC,UAAU,UAAU,OAAO;AAAA,IAC3B,gBAAgB,UAAU,OAAO;AAAA,EACnC,CAAC;AAGD,QAAM,mBAAmB,MAAM,gBAAgB,UAAU,OAAO;AAGhE,MAAI,CAAC,OAAO,UAAU,OAAO,aAAa,KAAK;AAC7C,WAAO;AAAA,MACL,QAAQ;AAAA,MACR,eAAe;AAAA,MACf,QAAQ,OAAO;AAAA,MACf,UAAU,kBAAkB,UAAU,gBAAgB,OAAO,UAAU;AAAA,IACzE;AAAA,EACF;AAGA,MAAI,CAAC,KAAK,UAAU,KAAK,aAAa,KAAK;AACzC,WAAO;AAAA,MACL,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,UAAU,MAAM,WAAW,UAAU,KAAK,MAAM;AAAA,IAClD;AAAA,EACF;AAGA,MAAI,CAAC,WAAW,QAAQ;AACtB,WAAO;AAAA,MACL,QAAQ;AAAA,MACR,UAAU,WAAW,cAAc;AAAA,MACnC,QAAQ,WAAW;AAAA,IACrB;AAAA,EACF;AAGA,MAAI,gBAAgB;AACpB,QAAM,WAAqB,CAAC;AAG5B,MAAI,WAAW,UAAU,WAAW,aAAa,KAAK;AACpD,aAAS,KAAK,WAAW,cAAc,yCAAyC;AAAA,EAClF;AAGA,MAAI,iBAAiB,eAAe,OAAO;AACzC,aAAS,KAAK,sDAAsD;AAAA,EACtE;AAGA,kBAAgB,qBAAqB,eAAe,MAAM;AAG1D,MAAI,SAAS,SAAS,GAAG;AACvB,oBAAgB,GAAG,aAAa;AAAA;AAAA,yBAAoB,SAAS,KAAK,GAAG,CAAC;AAAA,EACxE;AAEA,SAAO;AAAA,IACL,QAAQ;AAAA,IACR,UAAU;AAAA,IACV,SAAS,SAAS,SAAS,IAAI,SAAS,KAAK,GAAG,IAAI;AAAA,IACpD,UAAU;AAAA,MACR,cAAc,OAAO;AAAA,MACrB,iBAAiB,iBAAiB;AAAA,MAClC,WAAW,cAAc,YAAY,EAAE,SAAS,QAAQ;AAAA,IAC1D;AAAA,EACF;AACF;AAMA,IAAM,iBAAiB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAavB,SAAS,kBACP,UACA,SACA,YACQ;AACR,SAAO,GAAG,QAAQ;AAAA;AAAA,EAElB,OAAO;AAAA;AAAA,EAEP,aAAa,mBAAmB,UAAU,KAAK,EAAE;AACnD;AAKA,eAAe,WAAW,UAAkB,QAAkC;AAG5E,SAAO,GAAG,QAAQ;AAAA;AAAA,mDAE+B,UAAU,sBAAsB;AACnF;","names":[]}